# Task 3.1: AI Service Setup & LLM Integration

## 1. 개요 (Overview)

- **Task ID**: 3.1
- **목표**: `ai-service`를 활성화하고, LangChain을 도입하여 LLM(Large Language Model)과의 연동 기반을 마련한다.
- **선행 작업**: Node.js 기반의 NestJS 환경 확인 (Python 런타임 제외)

## 2. 상세 요구사항 (Requirements)

1.  **의존성 추가**: `ai-service`에서 사용할 LangChain 및 AI 관련 패키지 설치.
    - `@langchain/core`, `@langchain/community`
    - `@langchain/openai` 또는 `@langchain/google-genai` (설정으로 선택 가능하도록)
2.  **환경 변수 설정**: LLM Provider 및 API Key 관리를 위한 `ConfigModule` 설정.
3.  **LlmService 구현**:
    - LangChain의 `ChatModel`을 래핑하여 공통 인터페이스 제공.
    - 기본적인 `chat()` 메서드 구현.
4.  **API Endpoint**:
    - `POST /api/ai/chat`: 사용자 질문을 입력받아 LLM 응답 반환.

## 3. 기술적 의사결정 (Technical Decisions)

- **Framework**: NestJS (기존 아키텍처 준수).
- **Library**: LangChain.js (표준화된 LLM 인터페이스).
- **Python 제외**: `pyproject.toml`이 존재하나, 현재 프로젝트 표준인 NestJS/TypeScript로 통일하여 운영 복잡도 감소. 필요한 경우 추후 Python 마이크로서비스로 분리 논의.

## 4. 작업 단위 (Work Units)

1.  **Package Installation**: Root `package.json`에 LangChain 관련 의존성 추가.
2.  **Module Setup**: `AiModule`, `LlmModule` 생성 및 설정.
3.  **Service Implementation**: `LlmService` - LangChain ChatModel 연동.
4.  **Controller Implementation**: `AiController` - REST API 노출.
5.  **Verification**: 단순 echo 또는 LLM 응답 테스트 (Mocking 가능).

## 5. 승인 기준 (Acceptance Criteria)

- [ ] `ai-service`가 정상적으로 빌드 및 실행되어야 한다.
- [ ] `/api/ai/chat` 엔드포인트를 통해 요청을 보내면 응답이 와야 한다. (API Key가 없으면 Mock 응답이라도 성공해야 함)
- [ ] LangChain 패키지가 정상적으로 로드되어야 한다.
